{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re, requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class DotaLatestInfo:\n",
    "    hero_df=None\n",
    "    df_advantage=None\n",
    "    df_disadvantage=None\n",
    "    df_lane_position=None\n",
    "    df_item_hero=None\n",
    "    def __init__(self):\n",
    "        self.push_info()\n",
    "    def push_info(self):\n",
    "        \n",
    "\n",
    "        print('This will take about 5 minutes!!')\n",
    "        \n",
    "        \n",
    "        dota_url='https://www.dotabuff.com/heroes/meta'\n",
    "        r   = requests.get(dota_url, headers={'user-agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        table = soup('table')\n",
    "        \n",
    "        self.hero_df = pd.read_html(str(table))[0]\n",
    "        del self.hero_df['Hero']\n",
    "        #rename columns\n",
    "        self.hero_df.columns = ['Hero', 'Pick%_Crusader', 'Win%_Crusader', 'Pick%_Crusader_Archon','Win%_Crusader_Archon',\n",
    "                          'Pick%_Legend','Win%_Legend','Pick%Ancient','Win%Ancient','Pick%Divine_Imortal','Win%Divine_Imortal']\n",
    "        \n",
    "        #all of our columns are objects, we have to remove the '%' character and then transform it to numerical value\n",
    "        for y in self.hero_df.columns:\n",
    "            if y !='Hero':\n",
    "                for w in range(len(self.hero_df[y])):\n",
    "                    self.hero_df[y][w] = self.hero_df[y][w].translate({ord(i):None for i in '%'})\n",
    "                    self.hero_df[y][w]=pd.to_numeric(self.hero_df[y][w])\n",
    "        self.hero_df.reset_index(inplace=True)\n",
    "\n",
    "        \n",
    "        #Now we need to create  our table with the info about witch heroes are best against and worst against\n",
    "        #Since we are dealing with 122 heroes, i would need 121 html to get the info\n",
    "        # this is a tedious task to get one by one. So first we need to create a list with all of our heroes:\n",
    "        #We will create in a manner that, even if the heroes meta change, we still be abe to use this script\n",
    "        #Creating the list...\n",
    "        hero_name = self.hero_df['Hero']\n",
    "\n",
    "        #If we take a look, the html for each hero is like that: <https://www.dotabuff.com/heroes/HERO-NAME>\n",
    "        # letters should be all in lower case, instead of space between the name it should be \"-\". Let's change our hero_name object:\n",
    "        hero_name_new = []\n",
    "        for i in range(len(hero_name)):\n",
    "            if \"-\" in hero_name[i]:\n",
    "                hero_name_new.append(hero_name[i].lower())\n",
    "            elif \"'\" in hero_name[i]:\n",
    "                hero_name_new.append(hero_name[i].lower().replace(\"'\",\"\").replace(' ','-'))\n",
    "            else:\n",
    "                hero_name_new.append(hero_name[i].lower().replace(' ',\"-\"))\n",
    "        \n",
    "        #Now we can create several soups for our heroes\n",
    "        #First, we are going to create a list of urls:\n",
    "        heroes_url = []\n",
    "        for i in range(len(hero_name_new)):\n",
    "            heroes_url.append('https://www.dotabuff.com/heroes/'+hero_name_new[i])\n",
    "        \n",
    "        #Now let's create our requests and our soups. We are going to use time.sleep function, since we are not wanting to make a ddos attack:\n",
    "        requests_hero   = []\n",
    "\n",
    "        for i in range(len(heroes_url)):\n",
    "            time.sleep(0.1)\n",
    "            requests_hero.append(requests.get(heroes_url[i], headers={'user-agent': 'Mozilla/5.0'}))\n",
    "        \n",
    "        #Ok, now let's create our soups!\n",
    "        soups_heroes =[] \n",
    "        for i in range(len(requests_hero)):\n",
    "            soups_heroes.append(BeautifulSoup(requests_hero[i].content))\n",
    "        list_advantage=[]\n",
    "        for i in range(len(soups_heroes)):\n",
    "\n",
    "            a = pd.read_html(str(soups_heroes[i]('table')))[3]\n",
    "            a['MetaHero'] = self.hero_df['Hero'][i]\n",
    "            del a['Hero']\n",
    "            a.rename(columns = {'Hero.1':'Better against'},inplace = True)\n",
    "            a['MetaHero'] = self.hero_df['Hero'][i]\n",
    "            list_advantage.append(a)\n",
    "            self.df_advantage = pd.concat(list_advantage)\n",
    "            self.df_advantage.reset_index(drop=True,inplace=True)\n",
    "            for w in self.df_advantage.columns:\n",
    "                if ((w!='Better against') and(w!='Matches') and(w!='MetaHero')):\n",
    "                    for z in range(len(self.df_advantage.index)):\n",
    "                        s =  self.df_advantage.at[z,w].replace('%','')\n",
    "                        self.df_advantage.at[z,w] = pd.to_numeric(s)\n",
    "\n",
    "\n",
    "        list_disadvantage=[]\n",
    "        for i in range(len(soups_heroes)):\n",
    "\n",
    "            a = pd.read_html(str(soups_heroes[i]('table')))[4]\n",
    "            a['MetaHero'] = self.hero_df['Hero'][i]\n",
    "            del a['Hero']\n",
    "            a.rename(columns = {'Hero.1':'Worst against'},inplace = True)\n",
    "\n",
    "            list_disadvantage.append(a)\n",
    "            self.df_disadvantage = pd.concat(list_disadvantage)\n",
    "            self.df_disadvantage.reset_index(drop=True,inplace=True)\n",
    "            for w in self.df_disadvantage.columns:\n",
    "                if ((w!='Worst against') and(w!='Matches') and(w!='MetaHero')):\n",
    "                    for z in range(len(self.df_disadvantage.index)):\n",
    "                        s =  self.df_disadvantage.at[z,w].replace('%','')\n",
    "                        self.df_disadvantage.at[z,w] = pd.to_numeric(s)\n",
    "\n",
    "        list_lane_position=[]\n",
    "        for i in range(len(soups_heroes)):\n",
    "            a = pd.read_html(str(soups_heroes[i]('table')))[1]\n",
    "            a['MetaHero'] = self.hero_df['Hero'][i]    \n",
    "            list_lane_position.append(a)\n",
    "            self.df_lane_position = pd.concat(list_lane_position)\n",
    "            self.df_lane_position.reset_index(drop=True,inplace=True)\n",
    "            for w in self.df_lane_position.columns:\n",
    "                if ((w!='Lane')and(w!='KDA Ratio')and(w!='GPM')and(w!='XPM')and(w!='MetaHero')):\n",
    "                    for z in range(len(self.df_lane_position.index)):\n",
    "                        s =  self.df_lane_position.at[z,w].replace('%','')\n",
    "                        self.df_lane_position.at[z,w] = pd.to_numeric(s)\n",
    "\n",
    "        list_item_hero=[]\n",
    "        for i in range(len(soups_heroes)):\n",
    "            a = pd.read_html(str(soups_heroes[i]('table')))[2]\n",
    "            a['MetaHero'] = self.hero_df['Hero'][i]\n",
    "            del a['Item']\n",
    "            a.rename(columns = {'Item.1':'Item'},inplace = True)\n",
    "            list_item_hero.append(a)\n",
    "            self.df_item_hero = pd.concat(list_item_hero)\n",
    "            self.df_item_hero.reset_index(drop=True,inplace=True)\n",
    "            for w in self.df_item_hero.columns:\n",
    "                if ((w!='Item')and(w!='Matches')and(w!='Wins')and(w!='MetaHero')):\n",
    "                    for z in range(len(self.df_item_hero.index)):\n",
    "                        s =  self.df_item_hero.at[z,w].replace('%','')\n",
    "                        self.df_item_hero.at[z,w] = pd.to_numeric(s)\n",
    "\n",
    "    def get_top5(self,by,elo):\n",
    "        if ((by =='Pick')and(elo=='Crusader')):\n",
    "            return self.hero_df.groupby(['Pick%_Crusader','Hero','Win%_Crusader']).sum().sort_values('Pick%_Crusader',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Pick')and(elo=='Crusader_Archon')):\n",
    "            return self.hero_df.groupby(['Pick%_Crusader_Archon','Hero','Win%_Crusader_Archon']).sum().sort_values('Pick%_Crusader_Archon',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Pick')and(elo=='Legend')):\n",
    "            return self.hero_df.groupby(['Pick%_Legend','Hero','Win%_Legend']).sum().sort_values('Pick%_Legend',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Pick')and (elo=='Ancient')):\n",
    "            return self.hero_df.groupby(['Pick%Ancient','Hero','Win%_Ancient']).sum().sort_values('Pick%Ancient',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Pick')and(elo=='Divine_Imortal')):\n",
    "            return self.hero_df.groupby(['Pick%Divine_Imortal','Hero','Win%Divine_Imortal']).sum().sort_values('Pick%Divine_Imortal',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Win')and(elo=='Crusader')):\n",
    "            return self.hero_df.groupby(['Win%_Crusader','Hero','Pick%_Crusader']).sum().sort_values('Win%_Crusader',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Win')and(elo=='Crusader_Archon')):\n",
    "            return self.hero_df.groupby(['Win%_Crusader_Archon','Hero','Pick%_Crusader_Archon']).sum().sort_values('Win%_Crusader_Archon',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Win')and(elo=='Legend')):\n",
    "            return self.hero_df.groupby(['Win%_Legend','Hero','Pick%_Legend']).sum().sort_values('Win%_Legend',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Win')and(elo=='Ancient')):\n",
    "            return self.hero_df.groupby(['Win%Ancient','Hero','Pick%Ancient']).sum().sort_values('Win%Ancient',ascending=False).head(5)\n",
    "\n",
    "        elif((by=='Win')and(elo=='Divine_Imortal')):\n",
    "            return self.hero_df.groupby(['Win%Divine_Imortal','Hero','Pick%Divine_Imortal']).sum().sort_values('Win%Divine_Imortal',ascending=False).head(5)\n",
    "        \n",
    "    def get_advantage_disadvantage(self,hero):\n",
    "        my_list=[]\n",
    "        for i in self.hero_df['Hero']:\n",
    "            for w in hero:\n",
    "                if w ==i:\n",
    "                    for w in hero:\n",
    "                        a=self.df_advantage[self.df_advantage['MetaHero']==w].join(self.df_disadvantage[self.df_disadvantage['MetaHero']==w],\n",
    "                                                                         how='left',lsuffix='_Advantage',rsuffix='_Disadvantage')\n",
    "                        my_list.append(a)\n",
    "                        my_df=pd.concat(my_list)\n",
    "                    return my_df\n",
    "                \n",
    "    def get_lane_position(self,by):\n",
    "        my_list=[]\n",
    "        for i in self.df_lane_position['MetaHero'].unique():\n",
    "            for w in by:\n",
    "                if w==i:\n",
    "                    a=self.df_lane_position[self.df_lane_position['MetaHero']==w].groupby(['Presence','Win Rate','KDA Ratio','GPM','XPM','MetaHero']).sum().sort_values('Win Rate',ascending=False)\n",
    "                    my_list.append(a)\n",
    "\n",
    "                    my_df=pd.concat(my_list)\n",
    "        return my_df\n",
    "    \n",
    "    def get_item_hero(self,hero):\n",
    "        my_list=[]\n",
    "        for i in self.hero_df['Hero']:\n",
    "            for w in hero:\n",
    "                if w==i:\n",
    "                    a = self.df_item_hero[self.df_item_hero['MetaHero']==w].groupby(['Win Rate','Item','MetaHero']).sum().sort_values('Win Rate',ascending=False)\n",
    "                    my_list.append(a)\n",
    "                    my_df=pd.concat(my_list)\n",
    "        return my_df\n",
    "    \n",
    "    def item_info(self,item):\n",
    "    \n",
    "        item_name=[]\n",
    "        for i in range(len(item)):\n",
    "\n",
    "            if \"'\" in item[i]:\n",
    "                item_name.append(item[i].lower().replace(\"'\",\"\").replace(' ','-'))\n",
    "            else:\n",
    "                item_name.append(item[i].lower().replace(' ','-'))\n",
    "\n",
    "        items_url = []\n",
    "        for i in range(len(item_name)):\n",
    "            items_url.append('https://www.dotabuff.com/items/'+item_name[i])\n",
    "\n",
    "\n",
    "        requests_item   = []\n",
    "\n",
    "        for i in range(len(items_url)):\n",
    "\n",
    "            requests_item.append(requests.get(items_url[i], headers={'user-agent': 'Mozilla/5.0'}))\n",
    "\n",
    "        soups_items =[] \n",
    "        for i in range(len(requests_item)):\n",
    "            soups_items.append(BeautifulSoup(requests_item[i].content))\n",
    "\n",
    "        for w in range(len(soups_items)):\n",
    "            print('\\033[1m' + soups_items[w].find(\"div\",class_='name').text + '\\033[0m','\\n',soups_items[w].find(\"div\",class_='stats').text)\n",
    "            print(soups_items[w].find(\"div\",class_='description').text)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
